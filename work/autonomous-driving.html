<!DOCTYPE html>
<!--  This site was created in Webflow. http://www.webflow.com  -->
<!--  Last Published: Wed Oct 30 2019 01:26:31 GMT+0000 (UTC)  -->
<html data-wf-page="5db5f63a32df59103665c3fb" data-wf-site="5d8c11000558613f561603d7">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-146491716-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-146491716-2');
  </script>

  <meta charset="utf-8">
  <title>autonomous-driving</title>
  <meta content="autonomous-driving" property="og:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="../css/normalize.css" rel="stylesheet" type="text/css">
  <link href="../css/webflow.css" rel="stylesheet" type="text/css">
  <link href="../css/whitney-li-portfolio.webflow.css" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic"]  }});</script>
  <!-- [if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif] -->
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="../images/favicon.png" rel="shortcut icon" type="image/x-icon">
  <link href="../images/webclip.png" rel="apple-touch-icon">
</head>
<body>
  <div data-collapse="medium" data-animation="default" data-duration="400" class="navigation w-nav">
    <div class="navigation-items"><a href="../index.html" class="logo-link w-nav-brand"><img src="../images/whitney-logo.png" width="58" alt="" class="logo-image"></a>
      <div class="navigation-wrap">
        <nav role="navigation" class="navigation-items w-nav-menu"><a href="../index.html" class="navigation-item w-nav-link">Portfolio</a><a href="../about.html" class="navigation-item w-nav-link">About</a></nav>
        <div class="menu-button w-nav-button"><img src="../images/menu-icon_1menu-icon.png" width="22" alt="" class="menu-icon"></div>
      </div>
    </div>
  </div>
  <div class="bottom-navigation"><a href="#rice-apps" class="nav-link">Self-Driving</a><a href="#audi-news" class="nav-link">Voting System</a><a href="#heart-heard" class="nav-link">Facebook Profile</a></div>
  <div id="rice-apps" class="section">
    <div class="container">
      <div class="w-layout-grid project-overview-grid">
        <div id="w-node-58f9a32087d4-3665c3fb">
          <h1 class="heading-jumbo">Design VUI for Self-Driving Car</h1>
          <div class="paragraph-light">VUI Design and Collaboration</div>
        </div>
        <div id="w-node-58f9a32087d9-3665c3fb">
          <div class="position-name-text">Project Overview</div>
          <div class="paragraph-light cc-position-name">We designed Esya, a Level Four automated car, which will utilize a variety of non-traditional interfaces, including impoverished, speech, gesture, and haptic interfaces to interact with its users. <br /><br />
          I will show only the VUI design for different systems, but you are welcome to read the full report <a href="https://docs.google.com/document/d/1OgRFmVdZdmMZ8VT26EgzHb8chbX2uAqFCjuFl_p1b70/edit?usp=sharing">here</a>
        </div>
        </div>
        <div id="w-node-58f9a32087de-3665c3fb">
          <div class="position-name-text">My Contributions</div>
          <div class="paragraph-light cc-position-name">This is my final project for non-traditional interfaces class. I’m responsible for designing the entertainment system and coordinating the overall speech interface functions across three systems (entertainment, operation, and environment).<br /><br />
            <em>Relevant Skills: Speech Interface Design, Mind Map, User Need Analysis</em>
          </div>
        </div>
      </div>

      <p>
        <h4>Need analysis</h4>
        We define five important functions that should be achieved by entertainment system:
        <ul>
        <li>Play music, podcasts, radios, and other soundtracks when requested by the user</li>
        <li>Show movies, TV shows and other videos when requested by the user</li>
        <li>Perform advanced search, such as find a relaxing music playlist or display movies that are good for families</li>
        <li>Operate on the ongoing task, such as adjust volume, pause, replay, show lyrics</li>
        <li>Display the information of surrounding areas such as nearby restaurants, tourist attractions or gas stations when requested by the user</li>
        </ul>
        Users can perform those functions through the following ways. <br />
        <h6>Operate on the phone</h6>
        Based on operational system, Esya will automatically connects to a phone at the initial setup. The user can operate on the phone directly. The music will be played through car stereo, and videos will be projected by AR to side windows.<br />
        To disconnect the phone, the user can either turn off the bluetooth or ask Esya to do so.<br />
        <h6>Talk to Esya </h6>
        Here is a flow chart of the speech interface for entertainment system.<br />
        <div class="image-block"><img src="../images/Esya flow.png" width="700" alt="">  </div><br />
        Here is the flow chart for environmental system:
        <div class="image-block"><img src="../images/Esya environment.png" width="700" alt="">  </div><br />
        Here is the flow chart for navigation system:
        <div class="image-block"><img src="../images/Esya navigation.png" width="700" alt="">  </div><br />
      </p>
      <h4>Discussion</h4>
      <p>
        Why speech interface for entertainment system?<br />
        We use speech interface process the majority of tasks because:
        <ul>
        <li style="font-weight: 400;"><span style="font-weight: 400;">Speech is a natural form of interaction, and Esya’s speaking voice is socially relatable, so it will contribute to user experience &nbsp;</span></li>
        <li style="font-weight: 400;"><span style="font-weight: 400;">Car is a private environment and noise level can be controlled</span></li>
        <li style="font-weight: 400;"><span style="font-weight: 400;">Good for passengers whose abilities to use their hands or eyes are limited</span></li>
        <li style="font-weight: 400;"><span style="font-weight: 400;">Relatively mature technology (e.g. Alexa, Google Home, Siri)</span></li>
        </ul>
        Potential issues with speech interface:
        <li>
          Only one person can talk when Esya is on, otherwise it may bring confusions
        </li>
        <li>
          To turn on Esya again, the user needs to be as loud as the music playing
        </li>
      </p>
    </div>
  </div>


  <div id="audi-news" class="section">
    <div class="container">
      <div class="w-layout-grid project-overview-grid">
        <div id="w-node-d5e55ed5b2c3-3665c3fb">
          <h1 class="heading-jumbo">Eye-Tracking Study for Voting System</h1>
          <div class="paragraph-light">Research Design, Eye-Tracking Study, Data Analysis</div>
        </div>
        <div id="w-node-d5e55ed5b2c8-3665c3fb">
          <div class="position-name-text">Project Overview</div>
          <div class="paragraph-light cc-position-name">In the case of ballots, there have been many famous cases of poorly-designed ballots leading to voter errors substantial enough to change the outcome of an entire election. This is likely due to subtle features of the ballot design interacting poorly with unanticipated voter strategies. <br /><br />
            To better understand people’s use of two alternative memory strategies, retrieval-based VS. recognition-based, we used eye-tracking techniques to examine the the way voters sought information on the display. <br /><br />
          We present evidence that voters in a mock election do, in fact, use both retrieval-and recognition-based strategies to cast votes, sometimes alternating between them. We then discuss the importance of considering these alternate cognitive strategies when designing user interfaces.<br /><br />
        This project was published as a Human Factors and Ergonomics Society (HFES) conference paper.</div>
        </div>
        <div id="w-node-d5e55ed5b2cd-3665c3fb">
          <div class="position-name-text">My Contributions</div>
          <div class="paragraph-light cc-position-name">I worked at Byrne lab as a research assistant for a year. For the fall semester, I worked on eye tracking data analysis from 16 subjects using the voting system on a computer. The goal of the analysis is to investigate which areas of the voting system interface (e.g. party, candidate, race) the subjects would fixate at, its frequency and time length, so that we can better understand where people pay attention to. <br /><br />
            For the spring semester, I built a paper ballot interface for eye-tracking studies and ran 20 user studies independently. The goal of the paper ballot interface is to build something similar to real life voting scenario to collect data on which area (race, party, candidate name) the subjects would fixate at, so that we can understand their voting strategies and compare the results with those of multi-race ballot that I analyzed previously.
          </div>
        </div>
      </div>
      <h4>Eye-tracking Data Analysis</h4>
      <p>
        <h5>Fixation script</h5>
        After cleaning and adding necessary columns on Excel, I wrote functions on Python to achieve the following:
        <li>
          decide whether the fixation is on the screen
        </li>
        <li>
          Calculate the distance of the fixation and each object in the screen, find the closest object, and record the distance
        </li>
        <li>
          Calculate the direction of the object and the fixation, both on X-axis and Y-axis
        </li>
        <li>
          Add these variables to the original data frame to create a new Excel file
        </li>
        <h5>Fixation analysis</h5>
        I first need to identify if there are any data skewed by eye tracker issues (e.g. constantly off the screen by a certain distance). So I plot the distribution of distance and direction for each subject, which ended up removing the data of subject 7 because of the low number of fixations.<br /><br />
        Afterwards, to understand the fixation pattern of subjects, I wrote functions to 1) count the number of fixations for each race and 2) count the number of fixation on party, race, and candidate for each race and subject. <br /><br />
        Based on the tables generated, most subjects fixated at the review page/ instruction page/ race 1 the most, and the fixations on subject 22-27 are also relatively large. <br /><br />
        Furthermore, subjects paid attention to different information when using the voting system. For instance, subject 12 looked at candidate name the most, then party, then race, while subject 6 looked at race the most, then party, then candidate.
        <div class="w-row">
          <div class="w-col w-col-6">
            <div class="image-block"><img src="../images/eye-track.png" width="400" alt="">
              <div class="text-under-image">Fixation analysis output for subject 14</div>
            </div>
          </div>
          <div class="w-col w-col-6">
            <div class="image-block"><img src="../images/eye-track2.png" width="400" alt="">
              <div class="text-under-image">Fixation analysis output for subject 7, which I deleted because of tracker issues</div>
            </div>
          </div>
        </div>

      </p>
    </div>
  </div>

  <div id="heart-heard" class="section">
    <div class="container">
      <div class="w-layout-grid project-overview-grid">
        <div id="w-node-f900b1553f24-3665c3fb">
          <h1 class="heading-jumbo">Perception of Facebook Profiles</h1>
          <div class="paragraph-light">Literature Review, Research Design, Data Analysis</div>
        </div>
        <div id="w-node-f900b1553f29-3665c3fb">
          <div class="position-name-text">Project Overview</div>
          <div class="paragraph-light cc-position-name">The purpose of this study is to determine whether or not attractiveness of profile pictures and number of Facebook friends impact the way others perceive profile owners’ emotional intelligence and social desirability. </div>
        </div>
        <div id="w-node-f900b1553f2e-3665c3fb">
          <div class="position-name-text">My Contributions</div>
          <div class="paragraph-light cc-position-name">I conducted literature review, designed experiment (including setting up the fake Facebook profiles), obtained IRB approval, recruited participants, coded data, analyzed results, created a poster and wrote a paper.</div>
        </div>
      </div>
      <h4>Hypotheses</h4>
      <p>
        <li>
          With respect to attractiveness, we predicted that the attractive profile owner would be considered more socially desirable, and this effect would be even greater with a high number of Facebook friends.
        </li>
        <li>
          With respect to attractiveness, we predicted that the attractive profile owner would receive higher ratings of emotional intelligence, and this effect would be even greater with a high number of Facebook friends.
        </li>
      </p>
      <h4>Method</h4>
      <p>
        Participants: 117 participants enrolled in Rice University Spring 2017 PSYC 339 and PSYC 340 classes (80 females, 34 males, 3 other)<br /><br />
        Experimental Groups: Participants were randomly assigned to one of four different conditions. <br /><br />
        1. Attractive profile picture, High number of friends (1,387)<br />
        2. Attractive profile picture, Low number of friends (362) <br />
        3. Average profile picture, High number of friends<br />
        4. Average profile picture, Low number of friends <br /><br />
        Survey: Participants completed a questionnaire that assessed their willingness to befriend the profile owner and rated emotional intelligence of the profile owner
      </p>
      <h4>Findings</h4>
      <p>
        See poster below.
      </p>
      <div class="image-block"><img src="../images/Facebook.png"  alt="">  </div>
  </div>


  <div class="footer-wrap">
    <div class="div-block-5"><img src="../images/up.png" width="31" alt="" class="image-5"><a href="../index.html" class="logo-link w-nav-brand"><img src="../images/whitney-logo.png" width="58" alt="" class="logo-image image-4"></a></div>
    <div class="footer-links"><a href="https://www.linkedin.com/in/yuntongli/" target="_blank" class="footer-item">Linkedin</a><a href="https://www.instagram.com/whitneyli1218/" target="_blank" class="footer-item">Instagram</a><a href="https://medium.com/@whitneyli" target="_blank" class="footer-item">Medium</a></div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.4.1.min.220afd743d.js" type="text/javascript" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
  <script src="../js/webflow.js" type="text/javascript"></script>
  <!-- [if lte IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif] -->
</body>
</html>
